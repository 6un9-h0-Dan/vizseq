(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{152:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return o})),a.d(t,"rightToc",(function(){return c})),a.d(t,"default",(function(){return s}));a(59),a(32),a(23),a(24),a(60),a(0);var r=a(175),n=a(176);function i(){return(i=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var r in a)Object.prototype.hasOwnProperty.call(a,r)&&(e[r]=a[r])}return e}).apply(this,arguments)}var o={id:"overview",title:"Overview",sidebar_label:"Overview"},c=[{value:"Task Coverage",id:"task-coverage",children:[]},{value:"Metric Coverage",id:"metric-coverage",children:[]},{value:"License",id:"license",children:[]}],b={rightToc:c},l="wrapper";function s(e){var t=e.components,a=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,["components"]);return Object(r.b)(l,i({},b,a,{components:t,mdxType:"MDXLayout"}),Object(r.b)("p",null,"VizSeq is a Python toolkit for visual analysis on text generation tasks like machine translation, summarization,\nimage captioning, speech translation and video description. It takes multi-modal sources,\ntext references as well as text predictions as inputs, and analyzes them visually\nin ",Object(r.b)("a",{href:Object(n.a)("docs/getting_started/ipynb_example")},"Jupyter Notebook")," or a built-in ",Object(r.b)("a",{href:Object(n.a)("docs/getting_started/web_app_example")},"Web App")," (the former has ",Object(r.b)("a",{href:Object(n.a)("docs/getting_started/fairseq_example")},"Fairseq integration"),"). VizSeq also provides a collection of ",Object(r.b)("a",{href:Object(n.a)("docs/features/metrics")},"multi-process scorers")," as a\nnormal Python package."),Object(r.b)("p",{align:"center"},Object(r.b)("img",{src:Object(n.a)("img/overview.png"),alt:"VizSeq Overview",width:"480",class:"center"})),Object(r.b)("p",null,"Please also see our ",Object(r.b)("a",{href:"https://arxiv.org/pdf/1909.05424.pdf",target:"_blank"},"paper")," for more details. To\ninstall VizSeq, check out the ",Object(r.b)("a",{href:Object(n.a)("docs/getting_started/installation")},"instructions")," here."),Object(r.b)("h2",{id:"task-coverage"},"Task Coverage"),Object(r.b)("p",null,"VizSeq accepts various source types, including text, image, audio, video or any combination of them. This covers a wide\nrange of text generation tasks, examples of which are listed below:"),Object(r.b)("table",null,Object(r.b)("thead",{parentName:"table"},Object(r.b)("tr",{parentName:"thead"},Object(r.b)("th",i({parentName:"tr"},{align:"left"}),"Source"),Object(r.b)("th",i({parentName:"tr"},{align:"left"}),"Example Tasks"))),Object(r.b)("tbody",{parentName:"table"},Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Text"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Machine translation, text summarization, dialog generation, grammatical error correction, open-domain question answering")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Image"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Image captioning, image question answering, optical character recognition")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Audio"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Speech recognition, speech translation")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Video"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Video description")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Multimodal"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Multimodal machine translation")))),Object(r.b)("h2",{id:"metric-coverage"},"Metric Coverage"),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Accelerated with multi-processing/multi-threading.")),Object(r.b)("table",null,Object(r.b)("thead",{parentName:"table"},Object(r.b)("tr",{parentName:"thead"},Object(r.b)("th",i({parentName:"tr"},{align:"left"}),"Type"),Object(r.b)("th",i({parentName:"tr"},{align:"left"}),"Metrics"))),Object(r.b)("tbody",{parentName:"table"},Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"N-gram-based"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"BLEU (",Object(r.b)("a",i({parentName:"td"},{href:"https://www.aclweb.org/anthology/P02-1040"}),"Papineni et al., 2002"),"), NIST (",Object(r.b)("a",i({parentName:"td"},{href:"http://www.mt-archive.info/HLT-2002-Doddington.pdf"}),"Doddington, 2002"),"), METEOR (",Object(r.b)("a",i({parentName:"td"},{href:"https://www.aclweb.org/anthology/W05-0909"}),"Banerjee et al., 2005"),"), TER (",Object(r.b)("a",i({parentName:"td"},{href:"http://mt-archive.info/AMTA-2006-Snover.pdf"}),"Snover et al., 2006"),"), RIBES (",Object(r.b)("a",i({parentName:"td"},{href:"https://www.aclweb.org/anthology/D10-1092"}),"Isozaki et al., 2010"),"), chrF (",Object(r.b)("a",i({parentName:"td"},{href:"https://www.aclweb.org/anthology/W15-3049"}),"Popovi\u0107 et al., 2015"),"), GLEU (",Object(r.b)("a",i({parentName:"td"},{href:"https://arxiv.org/pdf/1609.08144.pdf"}),"Wu et al., 2016"),"), ROUGE (",Object(r.b)("a",i({parentName:"td"},{href:"https://www.aclweb.org/anthology/W04-1013"}),"Lin, 2004"),"), CIDEr (",Object(r.b)("a",i({parentName:"td"},{href:"https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf"}),"Vedantam et al., 2015"),"), WER")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"Embedding-based"),Object(r.b)("td",i({parentName:"tr"},{align:"left"}),"LASER (",Object(r.b)("a",i({parentName:"td"},{href:"https://arxiv.org/pdf/1812.10464.pdf"}),"Artetxe and Schwenk, 2018"),"), BERTScore (",Object(r.b)("a",i({parentName:"td"},{href:"https://arxiv.org/pdf/1904.09675.pdf"}),"Zhang et al., 2019"),")")))),Object(r.b)("h2",{id:"license"},"License"),Object(r.b)("p",null,"VizSeq is licensed under ",Object(r.b)("a",{href:"https://github.com/facebookresearch/vizseq/blob/master/LICENSE",target:"_blank"},"MIT"),"."))}s.isMDXComponent=!0},174:function(e,t,a){"use strict";var r=a(0),n=a(61);t.a=function(){return Object(r.useContext)(n.a)}},175:function(e,t,a){"use strict";a.d(t,"a",(function(){return c})),a.d(t,"b",(function(){return p}));var r=a(0),n=a.n(r),i=n.a.createContext({}),o=function(e){var t=n.a.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):Object.assign({},t,e)),a},c=function(e){var t=o(e.components);return n.a.createElement(i.Provider,{value:t},e.children)};var b="mdxType",l={inlineCode:"code",wrapper:function(e){var t=e.children;return n.a.createElement(n.a.Fragment,{},t)}},s=Object(r.forwardRef)((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,c=e.parentName,b=function(e,t){var a={};for(var r in e)Object.prototype.hasOwnProperty.call(e,r)&&-1===t.indexOf(r)&&(a[r]=e[r]);return a}(e,["components","mdxType","originalType","parentName"]),s=o(a),p=r,d=s[c+"."+p]||s[p]||l[p]||i;return a?n.a.createElement(d,Object.assign({},{ref:t},b,{components:a})):n.a.createElement(d,Object.assign({},{ref:t},b))}));function p(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=s;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c[b]="string"==typeof e?e:r,o[1]=c;for(var p=2;p<i;p++)o[p]=a[p];return n.a.createElement.apply(null,o)}return n.a.createElement.apply(null,a)}s.displayName="MDXCreateElement"},176:function(e,t,a){"use strict";a.d(t,"a",(function(){return n}));a(177);var r=a(174);function n(e){var t=(Object(r.a)().siteConfig||{}).baseUrl,a=void 0===t?"/":t;if(!e)return e;return/^(https?:|\/\/)/.test(e)?e:e.startsWith("/")?a+e.slice(1):a+e}},177:function(e,t,a){"use strict";var r=a(9),n=a(25),i=a(94),o="".startsWith;r(r.P+r.F*a(95)("startsWith"),"String",{startsWith:function(e){var t=i(this,e,"startsWith"),a=n(Math.min(arguments.length>1?arguments[1]:void 0,t.length)),r=String(e);return o?o.call(t,r,a):t.slice(a,a+r.length)===r}})}}]);